{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pix2Pix (Image-to-Image Translation with Conditional Adversarial Networks)\n",
    "![img](../notebook_material/pix2pix.jpg)\n",
    "https://github.com/affinelayer/pix2pix-tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import package "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "'''Basic package'''\n",
    "import os\n",
    "# 告訴系統要第幾張卡被看到。 Ex. 硬體總共有8張顯卡，以下設定只讓系統看到第1張顯卡\n",
    "# 若沒設定，則 Tensorflow 在運行時，預設會把所有卡都佔用\n",
    "# 要看裝置內顯卡數量及目前狀態的話，請在終端機內輸入 \"nvidia-smi\"\n",
    "# 若你的裝置只有一張顯卡可以使用，可以忽略此設定\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "\n",
    "import cv2          #影像處理\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm_notebook as tqdm #進度條\n",
    "import matplotlib.pyplot as plt        #繪圖\n",
    "\n",
    "# 自定義 library\n",
    "from generator import data_generators\n",
    "from callbacks import *\n",
    "\n",
    "'''Tensorflow package'''\n",
    "import tensorflow as tf\n",
    "\n",
    "'''Data augmentation package'''\n",
    "from imgaug import augmenters as iaa\n",
    "import imgaug as ia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input image\n",
    "img_size = 256\n",
    "data_list = 'data_list/'\n",
    "\n",
    "# model\n",
    "model_name= 'pix2pix'\n",
    "batch_size = 5\n",
    "nb_epoch = 150\n",
    "n_batch = 368\n",
    "L1_lambda = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessed_img(id_list, aug = False):\n",
    "    x = []\n",
    "    y = []\n",
    "    file = []\n",
    "    \n",
    "    for idx, row in id_list.iterrows():\n",
    "        A = row['A']  #轉換前的影像\n",
    "        B = row['B']  #轉換後的影像\n",
    "        ID = row[0]\n",
    "        \n",
    "        A = cv2.imread(A)[:,:,::-1] # cv2 預設讀進來是 BGR, 我們要轉回 RGB\n",
    "        B = cv2.imread(B)[:,:,::-1]  \n",
    "        \n",
    "        # random crop: 將影像放大 30 pixel，再裁減回原始的大小\n",
    "        A = cv2.resize(A, (img_size+30, img_size+30))\n",
    "        B = cv2.resize(B, (img_size+30, img_size+30))\n",
    "        r_x = random.randint(0, 30)\n",
    "        r_y = random.randint(0, 30)\n",
    "        A = A[r_y:r_y+img_size, r_x:r_x+img_size, :]\n",
    "        B = B[r_y:r_y+img_size, r_x:r_x+img_size, :]\n",
    "        \n",
    "        seq = iaa.Sequential([\n",
    "            iaa.Fliplr(0.5)     # 有五成的機率會左右翻轉\n",
    "        ])\n",
    "        seq.to_deterministic()\n",
    " \n",
    "        A = seq.augment_image(A)\n",
    "        B = seq.augment_image(B)\n",
    "        \n",
    "        #像素值壓縮到 [-1, 1]\n",
    "        A = ((A.astype('float32') / 255) - 0.5)*2\n",
    "        B = ((B.astype('float32') / 255) - 0.5)*2\n",
    "        \n",
    "        x.append(A)\n",
    "        y.append(B)\n",
    "        \n",
    "        file.append(ID)\n",
    "        \n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return x, y, file\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callback "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_dict = {\n",
    "    'model_name' : model_name,\n",
    "    'checkpoint' : Model_checkpoint(os.path.join('model', model_name), save_best_only=False),\n",
    "    'train_batch_log' : History(['g_loss', 'd_loss']),\n",
    "    'val_batch_log' : History(['g_loss', 'd_loss']),\n",
    "    'history' : {\n",
    "        'train_g_loss':[],\n",
    "        'train_d_loss':[],\n",
    "        'val_g_loss':[],\n",
    "        'val_d_loss':[]\n",
    "    }\n",
    "}\n",
    "\n",
    "callback_dict = {\n",
    "    'on_session_begin':[], # start of a session\n",
    "    'on_batch_begin':[], # start of a training batch\n",
    "    'on_batch_end':[], # end of a training batch\n",
    "    'on_epoch_begin':[], # start of a epoch\n",
    "    'on_epoch_end':[\n",
    "        model_dict['checkpoint']\n",
    "    ], # end of a epoch\n",
    "    'on_session_end':[] # end of a session\n",
    "}\n",
    "callback_manager = Run_collected_functions(callback_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join(data_list, 'train.csv'))\n",
    "val_df = pd.read_csv(os.path.join(data_list, 'val.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generators = data_generators(batch_size, [train_df, val_df], preprocessed_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-53e806163112>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgenerators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_train_threads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/aiaGAN/python_GAN/03_Condition_GAN/generator.py\u001b[0m in \u001b[0;36mload_val\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mval_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_dfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-53812d420584>\u001b[0m in \u001b[0;36mpreprocessed_img\u001b[0;34m(id_list, aug)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mID\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# cv2 預設讀進來是 BGR, 我們要轉回 RGB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "generators.load_val()\n",
    "generators.start_train_threads()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定義 generator & discrminator \n",
    "<img src=\"../notebook_material/pix2pix_structure.png\" alt=\"Drawing\" align=\"center\" style=\"height: 350px;\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(x, dim, out_dim):\n",
    "    '''\n",
    "    論文當中的 generator 採用 U-Net，前半段 Encoder feature maps 連結到後半段 Decoder 對應 feature maps\n",
    "    '''\n",
    "    # encoder, decoder 每層 filter 數量\n",
    "    e_dims = [dim] + [dim*2] + [dim*4] + [dim*8]*5\n",
    "    d_dims = e_dims[::-1][1:]\n",
    "    e_list = []\n",
    "    \n",
    "    with tf.variable_scope('generator', reuse=tf.AUTO_REUSE):\n",
    "        # Encoder: 影像->特徵向量\n",
    "        # 請輸入程式碼\n",
    "        for i in range(8):\n",
    "            if i == 0:\n",
    "                x = tf.layers.conv2d(x,e_dims[i], 4, strides=2, padding='SAME')\n",
    "            elif i == 7:\n",
    "                x = tf.nn.leaky_relu(x)\n",
    "                x = tf.layers.conv2d(x, e_dims[i], 4, strides=2, padding='SAME')\n",
    "            else:\n",
    "                x = tf.nn.leaky_relu(x)\n",
    "                x = tf.layers.conv2d(x, e_dims[i], 4, strides=2, padding='SAME')\n",
    "                x = tf.layers.batch_normalization(x, training=True) #training打開增加隨機性\n",
    "            e_list.append(x)\n",
    "        e_list = e_list[::-1][1:]\n",
    "        \n",
    "        # Decoder: 特徵向量->影像\n",
    "        # 請輸入程式碼\n",
    "        for i in range(7):\n",
    "            x = tf.nn.relu(x)\n",
    "            x = tf.layers.conv2d_transpose(x, d_dim[i], 4, strides=2, padding='SAME')\n",
    "            x = tf.layers.batch_normalization(x, training=True)\n",
    "            \n",
    "            if i < 3:\n",
    "                x = tf.nn.dropout(x, 0.5) #增加隨機性\n",
    "            x = tf.concat([x, e_list[i]], 3) #[batch_size, height, weight, channel] 3就是沿著channel堆疊\n",
    "            \n",
    "        x = tf.nn.relu(x)\n",
    "        x = tf.layers.conv2d_transpose(x, out_dim, 4, strides=2, padding='SAME')\n",
    "        \n",
    "        x = tf.nn.tanh(x)\n",
    "    return x\n",
    "    \n",
    "def discriminator(x, dim):\n",
    "    with tf.variable_scope('discriminator', reuse=tf.AUTO_REUSE):\n",
    "        # 請輸入程式碼\n",
    "        x = tf.layers.conv2d(x, dim, 4, strides=2, padding='SAME')\n",
    "        x = tf.nn.leaky_relu(x)\n",
    "    \n",
    "        for i in range(3):\n",
    "            if i == 2:\n",
    "                stride = 1\n",
    "            else:\n",
    "                stride = 2\n",
    "            x = tf.layers.conv2d(x, dim(2**(i+1)), 4, strides=stride, padding='SAME' )\n",
    "            x = tf.layers.batch_normalization(x, training=True)\n",
    "            x = tf.nn.leaky_relu(x)\n",
    "        \n",
    "        x = tf.layers.flatten(x)\n",
    "        x = tf.layers.dense(x, 1)\n",
    "        \n",
    "    return x   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow- 建立靜態圖  \n",
    "**靜態圖**就像一張計畫圖一樣，定義計算流程。實際運算必須靠 **<span style=\"color:red;\"> Session </span>** 來執行\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd_dim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-23d8357db5da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m####  GAN model output  ####\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# 請完成以下程式碼\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mfake_img_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_img_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mreal_pair\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreal_img_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_img_B\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mfake_pair\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreal_img_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_img_B\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-693aba45e572>\u001b[0m in \u001b[0;36mgenerator\u001b[0;34m(x, dim, out_dim)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_transpose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_dim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'SAME'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_normalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'd_dim' is not defined"
     ]
    }
   ],
   "source": [
    "main_graph = tf.Graph()\n",
    "sess = tf.Session(graph=main_graph)\n",
    "\n",
    "with main_graph.as_default():\n",
    "    #### optimizer ####\n",
    "    G_opt = tf.train.AdamOptimizer(2e-4, beta1=0.5, beta2=0.999)\n",
    "    D_opt = tf.train.AdamOptimizer(2e-4, beta1=0.5, beta2=0.999)\n",
    "    \n",
    "    G_global_step = tf.Variable(0, name='global_step',trainable=False)\n",
    "    D_global_step = tf.Variable(0, name='global_step',trainable=False)\n",
    "    \n",
    "    #### placeholder ####\n",
    "    real_img_A = tf.placeholder(dtype=tf.float32, shape=(None, img_size, img_size, 3))\n",
    "    real_img_B = tf.placeholder(dtype=tf.float32, shape=(None, img_size, img_size, 3))\n",
    "    \n",
    "    ####  GAN model output  ####\n",
    "    # 請完成以下程式碼\n",
    "    fake_img_B = generator(real_img_A, 64, 3)\n",
    "    real_pair = tf.concat([real_img_A, real_img_B], 3)\n",
    "    fake_pair = tf.concat([real_img_A, fake_img_B], 3)\n",
    "    \n",
    "    D_fake = discriminator(fake_pair, 64)\n",
    "    D_real = discriminator(real_pair, 64)\n",
    "    \n",
    "    #### loss ####\n",
    "    # 請完成以下程式碼\n",
    "    D_real_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(D_real), logits=D_real))\n",
    "    D_fake_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.zeros_like(D_fake), logits=D_fake))\n",
    "    \n",
    "    D_loss = D_real_loss + D_fake_loss\n",
    "    G_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(D_fake), logits=D_fake)) + \\\n",
    "             L1_lambda*tf.reduce_mean(tf.abs(real_img_B - fake_img_B)) #L1 loss\n",
    "    \n",
    "    #### variable list ####\n",
    "    varList = tf.trainable_variables()\n",
    "    G_varList = [var for var in varList if 'generator' in var.name]\n",
    "    D_varList = [var for var in varList if 'discriminator' in var.name]\n",
    "        \n",
    "    #### update ####\n",
    "    G_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS, scope='generator') #使用內建的 batch normalization layer, 必須執行\n",
    "    with tf.control_dependencies(G_update_ops):                                  #tf.GraphKeys.UPDATE_OPS 才會更新到 BN 層的 mean, variance\n",
    "        G_update = G_opt.minimize(G_loss, var_list=G_varList, global_step=G_global_step) \n",
    "        \n",
    "    D_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS, scope='discriminator')\n",
    "    with tf.control_dependencies(D_update_ops):\n",
    "        D_update = D_opt.minimize(D_loss, var_list=D_varList, global_step=D_global_step)\n",
    "    \n",
    "    #### other ####\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow- 初始化模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### initialize model ####\n",
    "sess.run(init)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow- 實際執行模型訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot(img_pair):\n",
    "\n",
    "    fig, axarr = plt.subplots(4, 2, figsize=(5,10))\n",
    "    \n",
    "    for row in range(4):\n",
    "        real_img = ((img_pair[0][row]/2+0.5)*225).astype(np.uint8)\n",
    "        gen_img =  ((img_pair[1][row]/2+0.5)*225).astype(np.uint8)\n",
    "        axarr[row, 0].imshow(real_img) \n",
    "        axarr[row, 1].imshow(gen_img)\n",
    "        if row == 0:\n",
    "            axarr[row, 0].set_title('real image')\n",
    "            axarr[row, 1].set_title('generated image')\n",
    "    \n",
    "    # Fine-tune figure; hide x ticks for top plots and y ticks for right plots\n",
    "    plt.setp([a.get_xticklabels() for a in axarr[0, :]], visible=False)\n",
    "    plt.setp([a.get_yticklabels() for a in axarr[:, 1]], visible=False)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epoch_bar = tqdm(range(nb_epoch), desc=\"epoch\", unit=\"epoch\")\n",
    "for epoch in epoch_bar:\n",
    "\n",
    "    ### train ###\n",
    "    train_batch_bar = tqdm(range(n_batch), desc=\"train_batch\", unit=\"batch\", leave=False)\n",
    "\n",
    "    for batch in train_batch_bar:\n",
    "        x, y = generators.train_queue.get()\n",
    "        \n",
    "        # 執行 loss & update (train)\n",
    "        _, generator_loss = sess.run([G_update, G_loss], feed_dict={real_img_A:x, real_img_B:y })\n",
    "        model_dict['train_batch_log'].push({'g_loss':generator_loss})\n",
    "\n",
    "        if batch % 1 == 0:\n",
    "            x, y = generators.train_queue.get()\n",
    "            _, discriminator_loss = sess.run([D_update, D_loss], feed_dict={real_img_A:x, real_img_B:y })\n",
    "            model_dict['train_batch_log'].push({'d_loss':discriminator_loss})\n",
    "    \n",
    "    model_dict['history']['train_g_loss'].append(model_dict['train_batch_log'].avg_value('g_loss'))\n",
    "    model_dict['history']['train_d_loss'].append(model_dict['train_batch_log'].avg_value('d_loss'))\n",
    "    model_dict['train_batch_log'].reset()\n",
    "\n",
    "    ### val ###\n",
    "    val_batch_bar = tqdm(generators.iter_val(), total=generators.val_len, desc=\"val_batch\" , unit=\"batch\", leave=False)\n",
    "\n",
    "    val_image_pair = []\n",
    "    for x, y, length in val_batch_bar:\n",
    "        # 執行 loss and generate image (val)\n",
    "        # 小提醒： model 有使用 batch normalization。所以在非 training 階段， \n",
    "        # is_training要記得設定為 False。這樣 BN 層內的 mean, variance 才不會更新。\n",
    "        generator_loss, discriminator_loss, generate_img = \\\n",
    "        sess.run([G_loss, D_loss, fake_img_B], feed_dict={real_img_A: x, real_img_B: y})\n",
    "        # 選四對真實和生成的影像\n",
    "        val_image_pair = [y[:4], generate_img[:4]] \n",
    "        model_dict['val_batch_log'].push({'g_loss':generator_loss, 'd_loss':discriminator_loss}, length)\n",
    "\n",
    "\n",
    "    model_dict['history']['val_g_loss'].append(model_dict['val_batch_log'].avg_value('g_loss'))\n",
    "    model_dict['history']['val_d_loss'].append(model_dict['val_batch_log'].avg_value('d_loss'))\n",
    "    model_dict['val_batch_log'].reset()\n",
    "\n",
    "    \n",
    "    ### callback ###\n",
    "    print('Epoch: {}/{}'.format(epoch,nb_epoch))\n",
    "    print('train_G_loss: {:.3f}'.format(model_dict['history']['train_g_loss'][-1]),\n",
    "         'train_D_loss: {:.3f}'.format(model_dict['history']['train_d_loss'][-1]))\n",
    "    print('val_G_loss: {:.3f}'.format(model_dict['history']['val_g_loss'][-1]),\n",
    "         'val_D_loss: {:.3f}'.format(model_dict['history']['val_d_loss'][-1]))\n",
    "\n",
    "    \n",
    "    ### draw image ###\n",
    "    if epoch%2 == 0:\n",
    "        fig = plot(val_image_pair)\n",
    "        plt.show()\n",
    "        plt.close(fig)\n",
    "\n",
    "    callback_manager.run_on_epoch_end(val_loss = model_dict['history']['val_g_loss'][-1],\n",
    "                                      sess = sess,\n",
    "                                      saver = saver,\n",
    "                                      nth_epoch = epoch)\n",
    "    print('############################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os._exit(00)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
